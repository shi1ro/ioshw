{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset. It contains translations from English to Spanish, so swap the order of the phrases. Also add `\\t` and `\\n` as the start and stop tokens in the target sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = \"\\t\"\n",
    "stop_token = \"\\n\"\n",
    "\n",
    "with open(\"data/spa.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    samples = f.read().split(\"\\n\")\n",
    "\n",
    "samples = [sample.strip().split(\"\\t\")\n",
    "           for sample in samples if len(sample.strip()) > 0]\n",
    "\n",
    "samples = [(es, start_token + en + stop_token)\n",
    "           for en, es in samples if len(es) < 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99423"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ve.', '\\tGo.\\n'), ('Vete.', '\\tGo.\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(samples[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/nlpenv/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_samples, valid_samples = train_test_split(samples, train_size=.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79538"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19885"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the training vocabulary. Those are the only tokens you can trust the model will know how to handle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size: 101\n",
      "Output vocab size: 87\n"
     ]
    }
   ],
   "source": [
    "in_vocab = set()\n",
    "out_vocab = set()\n",
    "\n",
    "for in_seq, out_seq in train_samples:\n",
    "    in_vocab.update(in_seq)\n",
    "    out_vocab.update(out_seq)\n",
    "    \n",
    "in_vocab_size = len(in_vocab)\n",
    "out_vocab_size = len(out_vocab)",
    "\n",
    "print(\"Input vocab size:\", in_vocab_size)\n",
    "print(\"Output vocab size:\", out_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '«', '°', 'º', '»', '¿', 'Á', 'É', 'Ó', 'Ú', 'á', 'è', 'é', 'í', 'ñ', 'ó', 'ö', 'ú', 'ü', 'ś', 'с', '—', '€']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(in_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', '$', '%', \"'\", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', 'á', 'ã', 'è', 'é', 'ö', '‘', '’', '₂', '€']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(out_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through validation set and remove any tokens not present in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_samples = []\n",
    "for in_seq, out_seq in valid_samples:\n",
    "    tmp_in_seq = [c for c in in_seq if c in in_vocab]\n",
    "    tmp_out_seq = [c for c in out_seq if c in out_vocab]\n",
    "\n",
    "    tmp_samples.append((\"\".join(tmp_in_seq), \"\".join(tmp_out_seq)))\n",
    "    \n",
    "valid_samples = tmp_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build sequence-to-sequence model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, Masking\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "encoder_in = Input(shape=(None, in_vocab_size), name=\"encoder_in\")\n",
    "encoder_mask = Masking(name=\"encoder_mask\")(encoder_in)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, recurrent_dropout=0.3, name=\"encoder_lstm\")\n",
    "_, encoder_h, encoder_c = encoder_lstm(encoder_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_in = Input(shape=(None, out_vocab_size), name=\"decoder_in\")\n",
    "\n",
    "decoder_mask = Masking(name=\"decoder_mask\")(decoder_in)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,\n",
    "                    dropout=0.2, recurrent_dropout=0.3, name=\"decoder_lstm\")\n",
    "decoder_lstm_out, _, _ = decoder_lstm(decoder_mask, initial_state=[encoder_h, encoder_c])\n",
    "decoder_dense = Dense(out_vocab_size, activation=\"softmax\", name=\"decoder_out\")\n",
    "decoder_out = decoder_dense(decoder_lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_model = Model([encoder_in, decoder_in], decoder_out)\n",
    "seq2seq_model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_in (InputLayer)         (None, None, 101)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_in (InputLayer)         (None, None, 87)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_mask (Masking)          (None, None, 101)    0           encoder_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_mask (Masking)          (None, None, 87)     0           decoder_in[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 256), (None, 366592      encoder_mask[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  352256      decoder_mask[0][0]               \n",
      "                                                                 encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_out (Dense)             (None, None, 87)     22359       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 741,207\n",
      "Trainable params: 741,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create maps to convert characters to and from ints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_token2int = {token : i for i, token in enumerate(sorted(in_vocab))}\n",
    "out_token2int = {token : i for i, token in enumerate(sorted(out_vocab))}\n",
    "out_int2token = {i : token for (token, i) in out_token2int.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper functions for one-hot encoding sequences for use with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_batch_storage(batch_size, in_seq_len, out_seq_len):\n",
    "    \n",
    "    enc_in_seqs = np.zeros(\n",
    "        (batch_size, in_seq_len, in_vocab_size),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    dec_in_seqs = np.zeros(\n",
    "        (batch_size, out_seq_len, out_vocab_size),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    dec_out_seqs = np.zeros(\n",
    "        (batch_size, out_seq_len, out_vocab_size),\n",
    "        dtype=np.float32)\n",
    "        \n",
    "    return enc_in_seqs, dec_in_seqs, dec_out_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(samples):\n",
    "    batch_size = len(samples)\n",
    "    max_in_length = max([len(seq) for seq, _ in samples])\n",
    "    max_out_length = max([len(seq) for _, seq in samples])\n",
    "\n",
    "    enc_in_seqs, dec_in_seqs, dec_out_seqs = make_batch_storage(\n",
    "        batch_size, max_in_length, max_out_length)\n",
    "    \n",
    "    for i, (in_seq, out_seq) in enumerate(samples):\n",
    "        for time_step, token in enumerate(in_seq):\n",
    "            enc_in_seqs[i, time_step, in_token2int[token]] = 1\n",
    "\n",
    "        for time_step, token in enumerate(out_seq):\n",
    "            dec_in_seqs[i, time_step, out_token2int[token]] = 1\n",
    "\n",
    "        for time_step, token in enumerate(out_seq[1:]):\n",
    "            dec_out_seqs[i, time_step, out_token2int[token]] = 1\n",
    "            \n",
    "    return enc_in_seqs, dec_in_seqs, dec_out_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_util import Seq2SeqBatchGenerator\n",
    "\n",
    "batch_size = 64\n",
    "train_generator = Seq2SeqBatchGenerator(train_samples, batch_size, encode_batch)\n",
    "valid_generator = Seq2SeqBatchGenerator(valid_samples, batch_size, encode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 2.0665 - val_loss: 1.6023\n",
      "Epoch 2/500\n",
      "1247/1247 [==============================] - 80s 64ms/step - loss: 1.5773 - val_loss: 1.3537\n",
      "Epoch 3/500\n",
      "1247/1247 [==============================] - 80s 64ms/step - loss: 1.4031 - val_loss: 1.2136\n",
      "Epoch 4/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.3040 - val_loss: 1.1308\n",
      "Epoch 5/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.2386 - val_loss: 1.0732\n",
      "Epoch 6/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.1886 - val_loss: 1.0281\n",
      "Epoch 7/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.1490 - val_loss: 0.9981\n",
      "Epoch 8/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.1178 - val_loss: 0.9625\n",
      "Epoch 9/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.0901 - val_loss: 0.9392\n",
      "Epoch 10/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.0677 - val_loss: 0.9171\n",
      "Epoch 11/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.0489 - val_loss: 0.8982\n",
      "Epoch 12/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.0320 - val_loss: 0.8855\n",
      "Epoch 13/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.0181 - val_loss: 0.8723\n",
      "Epoch 14/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 1.0046 - val_loss: 0.8598\n",
      "Epoch 15/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9935 - val_loss: 0.8507\n",
      "Epoch 16/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9827 - val_loss: 0.8413\n",
      "Epoch 17/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9740 - val_loss: 0.8320\n",
      "Epoch 18/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9654 - val_loss: 0.8243\n",
      "Epoch 19/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9576 - val_loss: 0.8158\n",
      "Epoch 20/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9501 - val_loss: 0.8100\n",
      "Epoch 21/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9433 - val_loss: 0.8039\n",
      "Epoch 22/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9366 - val_loss: 0.7982\n",
      "Epoch 23/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9308 - val_loss: 0.7929\n",
      "Epoch 24/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9255 - val_loss: 0.7843\n",
      "Epoch 25/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9194 - val_loss: 0.7805\n",
      "Epoch 26/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9145 - val_loss: 0.7768\n",
      "Epoch 27/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9097 - val_loss: 0.7720\n",
      "Epoch 28/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9049 - val_loss: 0.7676\n",
      "Epoch 29/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.9003 - val_loss: 0.7640\n",
      "Epoch 30/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8965 - val_loss: 0.7592\n",
      "Epoch 31/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8921 - val_loss: 0.7542\n",
      "Epoch 32/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8887 - val_loss: 0.7513\n",
      "Epoch 33/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8837 - val_loss: 0.7467\n",
      "Epoch 34/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8811 - val_loss: 0.7446\n",
      "Epoch 35/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8777 - val_loss: 0.7402\n",
      "Epoch 36/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8738 - val_loss: 0.7370\n",
      "Epoch 37/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8706 - val_loss: 0.7343\n",
      "Epoch 38/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8671 - val_loss: 0.7305\n",
      "Epoch 39/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8642 - val_loss: 0.7276\n",
      "Epoch 40/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8620 - val_loss: 0.7258\n",
      "Epoch 41/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8582 - val_loss: 0.7235\n",
      "Epoch 42/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8566 - val_loss: 0.7195\n",
      "Epoch 43/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8529 - val_loss: 0.7161\n",
      "Epoch 44/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8501 - val_loss: 0.7140\n",
      "Epoch 45/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8475 - val_loss: 0.7119\n",
      "Epoch 46/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8443 - val_loss: 0.7106\n",
      "Epoch 47/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8431 - val_loss: 0.7077\n",
      "Epoch 48/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8403 - val_loss: 0.7068\n",
      "Epoch 49/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8382 - val_loss: 0.7023\n",
      "Epoch 50/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8357 - val_loss: 0.6999\n",
      "Epoch 51/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8341 - val_loss: 0.6994\n",
      "Epoch 52/500\n",
      "1247/1247 [==============================] - 82s 66ms/step - loss: 0.8318 - val_loss: 0.6975\n",
      "Epoch 53/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8303 - val_loss: 0.6938\n",
      "Epoch 54/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8271 - val_loss: 0.6930\n",
      "Epoch 55/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8251 - val_loss: 0.6903\n",
      "Epoch 56/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8242 - val_loss: 0.6883\n",
      "Epoch 57/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8220 - val_loss: 0.6879\n",
      "Epoch 58/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8203 - val_loss: 0.6864\n",
      "Epoch 59/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8182 - val_loss: 0.6836\n",
      "Epoch 60/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8170 - val_loss: 0.6808\n",
      "Epoch 61/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8149 - val_loss: 0.6799\n",
      "Epoch 62/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8131 - val_loss: 0.6791\n",
      "Epoch 63/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8114 - val_loss: 0.6772\n",
      "Epoch 64/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8093 - val_loss: 0.6758\n",
      "Epoch 65/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8084 - val_loss: 0.6744\n",
      "Epoch 66/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8069 - val_loss: 0.6721\n",
      "Epoch 67/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8052 - val_loss: 0.6708\n",
      "Epoch 68/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8036 - val_loss: 0.6702\n",
      "Epoch 69/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.8027 - val_loss: 0.6712\n",
      "Epoch 70/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7995 - val_loss: 0.6661\n",
      "Epoch 71/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7989 - val_loss: 0.6652\n",
      "Epoch 72/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7976 - val_loss: 0.6644\n",
      "Epoch 73/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7961 - val_loss: 0.6638\n",
      "Epoch 74/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7953 - val_loss: 0.6618\n",
      "Epoch 75/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7944 - val_loss: 0.6595\n",
      "Epoch 76/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7930 - val_loss: 0.6585\n",
      "Epoch 77/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7914 - val_loss: 0.6568\n",
      "Epoch 78/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7897 - val_loss: 0.6563\n",
      "Epoch 79/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7888 - val_loss: 0.6559\n",
      "Epoch 80/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7880 - val_loss: 0.6534\n",
      "Epoch 81/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7868 - val_loss: 0.6525\n",
      "Epoch 82/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7860 - val_loss: 0.6518\n",
      "Epoch 83/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7846 - val_loss: 0.6501\n",
      "Epoch 84/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7837 - val_loss: 0.6512\n",
      "Epoch 85/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7824 - val_loss: 0.6479\n",
      "Epoch 86/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7809 - val_loss: 0.6484\n",
      "Epoch 87/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7800 - val_loss: 0.6483\n",
      "Epoch 88/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7791 - val_loss: 0.6460\n",
      "Epoch 89/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7780 - val_loss: 0.6438\n",
      "Epoch 90/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7775 - val_loss: 0.6446\n",
      "Epoch 91/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7763 - val_loss: 0.6435\n",
      "Epoch 92/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7747 - val_loss: 0.6417\n",
      "Epoch 93/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7749 - val_loss: 0.6411\n",
      "Epoch 94/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7732 - val_loss: 0.6391\n",
      "Epoch 95/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7729 - val_loss: 0.6397\n",
      "Epoch 96/500\n",
      "1247/1247 [==============================] - 80s 65ms/step - loss: 0.7712 - val_loss: 0.6383\n",
      "Epoch 97/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7702 - val_loss: 0.6379\n",
      "Epoch 98/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7698 - val_loss: 0.6364\n",
      "Epoch 99/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7688 - val_loss: 0.6350\n",
      "Epoch 100/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7677 - val_loss: 0.6370\n",
      "Epoch 101/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7678 - val_loss: 0.6337\n",
      "Epoch 102/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7661 - val_loss: 0.6346\n",
      "Epoch 103/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7651 - val_loss: 0.6329\n",
      "Epoch 104/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7654 - val_loss: 0.6325\n",
      "Epoch 105/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7636 - val_loss: 0.6310\n",
      "Epoch 106/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7635 - val_loss: 0.6335\n",
      "Epoch 107/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7620 - val_loss: 0.6297\n",
      "Epoch 108/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7611 - val_loss: 0.6286\n",
      "Epoch 109/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7608 - val_loss: 0.6285\n",
      "Epoch 110/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7606 - val_loss: 0.6286\n",
      "Epoch 111/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7592 - val_loss: 0.6273\n",
      "Epoch 112/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7579 - val_loss: 0.6256\n",
      "Epoch 113/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7577 - val_loss: 0.6254\n",
      "Epoch 114/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7571 - val_loss: 0.6244\n",
      "Epoch 115/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7560 - val_loss: 0.6239\n",
      "Epoch 116/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7556 - val_loss: 0.6243\n",
      "Epoch 117/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7549 - val_loss: 0.6234\n",
      "Epoch 118/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7543 - val_loss: 0.6234\n",
      "Epoch 119/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7542 - val_loss: 0.6221\n",
      "Epoch 120/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7532 - val_loss: 0.6205\n",
      "Epoch 121/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7522 - val_loss: 0.6206\n",
      "Epoch 122/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7515 - val_loss: 0.6202\n",
      "Epoch 123/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7513 - val_loss: 0.6213\n",
      "Epoch 124/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7510 - val_loss: 0.6188\n",
      "Epoch 125/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7492 - val_loss: 0.6182\n",
      "Epoch 126/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7490 - val_loss: 0.6174\n",
      "Epoch 127/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7483 - val_loss: 0.6185\n",
      "Epoch 128/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7487 - val_loss: 0.6177\n",
      "Epoch 129/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7477 - val_loss: 0.6155\n",
      "Epoch 130/500\n",
      "1247/1247 [==============================] - 80s 65ms/step - loss: 0.7470 - val_loss: 0.6135\n",
      "Epoch 131/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7457 - val_loss: 0.6141\n",
      "Epoch 132/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7456 - val_loss: 0.6138\n",
      "Epoch 133/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7447 - val_loss: 0.6134\n",
      "Epoch 134/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7445 - val_loss: 0.6125\n",
      "Epoch 135/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7437 - val_loss: 0.6122\n",
      "Epoch 136/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7436 - val_loss: 0.6120\n",
      "Epoch 137/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7431 - val_loss: 0.6118\n",
      "Epoch 138/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7419 - val_loss: 0.6116\n",
      "Epoch 139/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7413 - val_loss: 0.6108\n",
      "Epoch 140/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7402 - val_loss: 0.6114\n",
      "Epoch 141/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7407 - val_loss: 0.6074\n",
      "Epoch 142/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7401 - val_loss: 0.6084\n",
      "Epoch 143/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7398 - val_loss: 0.6069\n",
      "Epoch 144/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7388 - val_loss: 0.6070\n",
      "Epoch 145/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7379 - val_loss: 0.6061\n",
      "Epoch 146/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7379 - val_loss: 0.6059\n",
      "Epoch 147/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7373 - val_loss: 0.6047\n",
      "Epoch 148/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7366 - val_loss: 0.6045\n",
      "Epoch 149/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7361 - val_loss: 0.6043\n",
      "Epoch 150/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7350 - val_loss: 0.6031\n",
      "Epoch 151/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7346 - val_loss: 0.6034\n",
      "Epoch 152/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7339 - val_loss: 0.6022\n",
      "Epoch 153/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7343 - val_loss: 0.6023\n",
      "Epoch 154/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7338 - val_loss: 0.6028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7332 - val_loss: 0.6025\n",
      "Epoch 156/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7330 - val_loss: 0.6008\n",
      "Epoch 157/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7325 - val_loss: 0.5998\n",
      "Epoch 158/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7323 - val_loss: 0.6006\n",
      "Epoch 159/500\n",
      "1247/1247 [==============================] - 80s 65ms/step - loss: 0.7313 - val_loss: 0.5996\n",
      "Epoch 160/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7302 - val_loss: 0.5998\n",
      "Epoch 161/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7299 - val_loss: 0.5997\n",
      "Epoch 162/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7296 - val_loss: 0.5982\n",
      "Epoch 163/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7289 - val_loss: 0.5977\n",
      "Epoch 164/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7284 - val_loss: 0.5978\n",
      "Epoch 165/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7286 - val_loss: 0.5990\n",
      "Epoch 166/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7281 - val_loss: 0.5979\n",
      "Epoch 167/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7280 - val_loss: 0.5967\n",
      "Epoch 168/500\n",
      "1247/1247 [==============================] - 80s 65ms/step - loss: 0.7275 - val_loss: 0.5953\n",
      "Epoch 169/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7267 - val_loss: 0.5943\n",
      "Epoch 170/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7258 - val_loss: 0.5946\n",
      "Epoch 171/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7258 - val_loss: 0.5953\n",
      "Epoch 172/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7254 - val_loss: 0.5969\n",
      "Epoch 173/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7248 - val_loss: 0.5930\n",
      "Epoch 174/500\n",
      "1247/1247 [==============================] - 80s 65ms/step - loss: 0.7242 - val_loss: 0.5941\n",
      "Epoch 175/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7243 - val_loss: 0.5937\n",
      "Epoch 176/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7230 - val_loss: 0.5931\n",
      "Epoch 177/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7231 - val_loss: 0.5932\n",
      "Epoch 178/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7222 - val_loss: 0.5923\n",
      "Epoch 179/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7231 - val_loss: 0.5905\n",
      "Epoch 180/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7229 - val_loss: 0.5927\n",
      "Epoch 181/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7215 - val_loss: 0.5917\n",
      "Epoch 182/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7215 - val_loss: 0.5907\n",
      "Epoch 183/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7207 - val_loss: 0.5907\n",
      "Epoch 184/500\n",
      "1247/1247 [==============================] - 81s 65ms/step - loss: 0.7204 - val_loss: 0.5910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd84cb76e10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "seq2seq_model.fit_generator(train_generator, epochs=500,\n",
    "                            validation_data=valid_generator,\n",
    "                            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create encoder/decoder models for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_encoder = Model(encoder_in, [encoder_h, encoder_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_in (InputLayer)      (None, None, 101)         0         \n",
      "_________________________________________________________________\n",
      "encoder_mask (Masking)       (None, None, 101)         0         \n",
      "_________________________________________________________________\n",
      "encoder_lstm (LSTM)          [(None, 256), (None, 256) 366592    \n",
      "=================================================================\n",
      "Total params: 366,592\n",
      "Trainable params: 366,592\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inf_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_dec_h_in = Input(shape=(latent_dim,), name=\"decoder_h_in\")\n",
    "inf_dec_c_in = Input(shape=(latent_dim,), name=\"decoder_c_in\")\n",
    "\n",
    "inf_dec_lstm_out, inf_dec_h_out, inf_dec_c_out = decoder_lstm(\n",
    "    decoder_in, initial_state=[inf_dec_h_in, inf_dec_c_in])\n",
    "\n",
    "inf_dec_out = decoder_dense(inf_dec_lstm_out)\n",
    "\n",
    "inf_decoder = Model(\n",
    "    [decoder_in, inf_dec_h_in, inf_dec_c_in],\n",
    "    [inf_dec_out, inf_dec_h_out, inf_dec_c_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_in (InputLayer)         (None, None, 87)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_h_in (InputLayer)       (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_c_in (InputLayer)       (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 256),  352256      decoder_in[0][0]                 \n",
      "                                                                 decoder_h_in[0][0]               \n",
      "                                                                 decoder_c_in[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_out (Dense)             (None, None, 87)     22359       decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 374,615\n",
      "Trainable params: 374,615\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inf_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test trained model on the first 100 samples from both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max output length:  87\n"
     ]
    }
   ],
   "source": [
    "max_out_seq_len = max([len(seq) for _, seq in samples])\n",
    "print(\"Max output length: \", max_out_seq_len)\n",
    "\n",
    "start_token_idx = out_token2int[start_token]\n",
    "stop_token_idx = out_token2int[stop_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sequence(one_hot_seq, encoder, decoder):\n",
    "    encoding = encoder.predict(one_hot_seq)\n",
    "\n",
    "    decoder_in = np.zeros((1, 1, out_vocab_size), dtype=np.float32)\n",
    "\n",
    "    translated_text = ''\n",
    "    done_decoding = False\n",
    "    decoded_idx = start_token_idx\n",
    "    while not done_decoding:\n",
    "        decoder_in[0, 0, decoded_idx] = 1\n",
    "        decoding, h, c = decoder.predict([decoder_in] + encoding)\n",
    "        encoding = [h, c]\n",
    "        decoder_in[0, 0, decoded_idx] = 0\n",
    "\n",
    "        decoded_idx = np.argmax(decoding[0, -1, :])\n",
    "        \n",
    "        if decoded_idx == stop_token_idx:\n",
    "            done_decoding = True\n",
    "        else:\n",
    "            translated_text += out_int2token[decoded_idx]\n",
    "\n",
    "        if len(translated_text) >= max_out_seq_len:\n",
    "            done_decoding = True\n",
    "            \n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: A todos nos gusta montar en bici.\n",
      "Dataset translation: \tWe all like cycling.\n",
      "\n",
      "Model output: We all like to go on his complain.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se rió de todos los chistes de Mary.\n",
      "Dataset translation: \tTom laughed at all of Mary's jokes.\n",
      "\n",
      "Model output: Tom laughed at Mary's eyes every morning.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom es un asqueroso.\n",
      "Dataset translation: \tTom is a creep.\n",
      "\n",
      "Model output: Tom is a good story.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cuál es tu meta en la vida?\n",
      "Dataset translation: \tWhat's your aim in life?\n",
      "\n",
      "Model output: What's your favorite in the window?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ella le escucha, aunque nadie más lo haga.\n",
      "Dataset translation: \tShe listens to him even though no one else does.\n",
      "\n",
      "Model output: She listened him not to help me anything.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ganar o perder no es la cuestión.\n",
      "Dataset translation: \tIt doesn't matter whether you win or not.\n",
      "\n",
      "Model output: Winning to do not the room is a complain.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Es un privilegio conocerte.\n",
      "Dataset translation: \tIt is a privilege to meet you.\n",
      "\n",
      "Model output: It's a pretty to get to you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Disculpe, se me han caído los palillos.\n",
      "Dataset translation: \tExcuse me, I dropped a chopstick.\n",
      "\n",
      "Model output: Excuse me the book who should go to school.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Hay un jardín delante de nuestra casa.\n",
      "Dataset translation: \tThere's a garden in front of our house.\n",
      "\n",
      "Model output: There's a new car from his house.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Corrí alrededor del campo.\n",
      "Dataset translation: \tI ran around the field.\n",
      "\n",
      "Model output: I ran away the car.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Nunca me he olvidado de ustedes.\n",
      "Dataset translation: \tI've never forgotten you.\n",
      "\n",
      "Model output: I've never forgot you for you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: A él le operaron la pierna izquierda.\n",
      "Dataset translation: \tHe had an operation on his left leg.\n",
      "\n",
      "Model output: He was open the way the rest.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: He hecho cosas cuestionables.\n",
      "Dataset translation: \tI've done questionable things.\n",
      "\n",
      "Model output: I've done the songs.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Soy estudiante de la universidad Hyogo.\n",
      "Dataset translation: \tI am a student at Hyogo University.\n",
      "\n",
      "Model output: I'm an experience in the videon.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo la impresión de que ella vendrá hoy.\n",
      "Dataset translation: \tI have an idea she will come today.\n",
      "\n",
      "Model output: I have to go to the station today today.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Está estudiando chino.\n",
      "Dataset translation: \tHe's studying Chinese.\n",
      "\n",
      "Model output: He is studying China.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Creo que va a llover hoy.\n",
      "Dataset translation: \tI think it's going to rain today.\n",
      "\n",
      "Model output: I think I'm going to be for today.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Un niño conducía un rebaño de ovejas.\n",
      "Dataset translation: \tA boy was driving a flock of sheep.\n",
      "\n",
      "Model output: A boy was a bath of the car was a bath.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy escribiendo una carta.\n",
      "Dataset translation: \tI'm writing a letter.\n",
      "\n",
      "Model output: I'm writing a car.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Te llevaré a nadar.\n",
      "Dataset translation: \tI will take you for a swim.\n",
      "\n",
      "Model output: I'll tell you again.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No falta nada.\n",
      "Dataset translation: \tNothing is missing.\n",
      "\n",
      "Model output: It isn't anything.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Yo le indiqué el camino.\n",
      "Dataset translation: \tI showed him the way.\n",
      "\n",
      "Model output: I told him the way.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué quieres decir?\n",
      "Dataset translation: \tWhatever do you mean?\n",
      "\n",
      "Model output: What do you want to tell you?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom necesita un cambio de decorado.\n",
      "Dataset translation: \tTom needs a change of scenery.\n",
      "\n",
      "Model output: Tom needs a chance car.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Pártelo a la mitad.\n",
      "Dataset translation: \tCut it in half.\n",
      "\n",
      "Model output: Stop the story.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Ya decidiste qué hacer?\n",
      "Dataset translation: \tHave you decided what to do yet?\n",
      "\n",
      "Model output: Did you decide to do what you did?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: El entusiasmo es contagioso.\n",
      "Dataset translation: \tEnthusiasm is contagious.\n",
      "\n",
      "Model output: The uncle is with the story.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tanto Tom como Mary estudian francés.\n",
      "Dataset translation: \tTom and Mary both study French.\n",
      "\n",
      "Model output: Tom has a little French and Mary.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Me gusta oír buena música.\n",
      "Dataset translation: \tI like listening to good music.\n",
      "\n",
      "Model output: I like to get much business.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Muchísimas gracias por el regalo.\n",
      "Dataset translation: \tThank you very much for your gift.\n",
      "\n",
      "Model output: Thank you for the problem to the right.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tú estás interfiriendo.\n",
      "Dataset translation: \tYou're interfering.\n",
      "\n",
      "Model output: You're interesting.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Acabo de verlo.\n",
      "Dataset translation: \tI saw him just now.\n",
      "\n",
      "Model output: I just told it.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Déjame pensar esto de nuevo.\n",
      "Dataset translation: \tLet me think this over.\n",
      "\n",
      "Model output: Let me tell this one of that.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Quiero creer que es así.\n",
      "Dataset translation: \tI'd like to think so.\n",
      "\n",
      "Model output: I want to believe that it's that.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Hagamos lo que dijo Tom.\n",
      "Dataset translation: \tLet's do what Tom said.\n",
      "\n",
      "Model output: Let's do what Tom wanted.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom una vez trabajó en una panadería.\n",
      "Dataset translation: \tTom once worked at a bakery.\n",
      "\n",
      "Model output: Tom was a work in the work in the world.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: A ellos les gusta jugar juntos.\n",
      "Dataset translation: \tThey enjoy playing together.\n",
      "\n",
      "Model output: They like to play tennis.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Quieres ir primero?\n",
      "Dataset translation: \tDo you want to go first?\n",
      "\n",
      "Model output: Do you want to go first?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Esperamos visitar España este verano.\n",
      "Dataset translation: \tWe are hoping to visit Spain this summer.\n",
      "\n",
      "Model output: We expect the very in the story in the window.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No entiendo lo que quiere decir.\n",
      "Dataset translation: \tI don't understand what you mean.\n",
      "\n",
      "Model output: I don't understand what I can say.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Cuando el agua se congela se vuelve hielo.\n",
      "Dataset translation: \tWhen water freezes it becomes ice.\n",
      "\n",
      "Model output: When he wants the story in the beautiful complain.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Alguna vez has comido insectos?\n",
      "Dataset translation: \tHave you ever eaten insects?\n",
      "\n",
      "Model output: Have you ever eaten some children?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Sal del agua.\n",
      "Dataset translation: \tGet out of the water.\n",
      "\n",
      "Model output: Get out of the box.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Él se quedó en mi hogar por tres semanas.\n",
      "Dataset translation: \tHe stayed at my place for three weeks.\n",
      "\n",
      "Model output: He stayed at my house in the street three days.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom hace su mejor esfuerzo.\n",
      "Dataset translation: \tTom is doing his best.\n",
      "\n",
      "Model output: Tom does his best friend.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Todo el mundo estuvo de acuerdo.\n",
      "Dataset translation: \tEverybody was in agreement.\n",
      "\n",
      "Model output: Everyone was afraid.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Si quieres tu dinero de vuelta, solo dilo.\n",
      "Dataset translation: \tIf you want your money back, just say so.\n",
      "\n",
      "Model output: If you want your money, the money is money.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Nadie me dijo nada.\n",
      "Dataset translation: \tNo one said anything to me.\n",
      "\n",
      "Model output: No one told me anything.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: A Tom le gusta estar rodeado de gente.\n",
      "Dataset translation: \tTom likes having people around.\n",
      "\n",
      "Model output: Tom likes being careful to be a complain.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tu madre se encuentra en estado crítico.\n",
      "Dataset translation: \tYour mother is in critical condition.\n",
      "\n",
      "Model output: Your mother is coming in the room.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Hay un gato debajo de la mesa.\n",
      "Dataset translation: \tThere's a cat under the table.\n",
      "\n",
      "Model output: There's a tall on the train.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Esto no es un sueño.\n",
      "Dataset translation: \tIt isn't a dream.\n",
      "\n",
      "Model output: This is not a dream.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Ellos son vuestros.\n",
      "Dataset translation: \tThey're yours.\n",
      "\n",
      "Model output: They're your friends.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Mañana, él alunizará.\n",
      "Dataset translation: \tTomorrow he lands on the moon.\n",
      "\n",
      "Model output: Tomorrow will be a little car.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Yo jugaré contigo.\n",
      "Dataset translation: \tI'll play with you.\n",
      "\n",
      "Model output: I'll play with you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom está gordo.\n",
      "Dataset translation: \tTom is fat.\n",
      "\n",
      "Model output: Tom is complaining.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Puedo reservar un vuelo a Chicago?\n",
      "Dataset translation: \tCan I reserve a flight to Chicago?\n",
      "\n",
      "Model output: Can I get a good control Chinese?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Él asistió a muchas ceremonias.\n",
      "Dataset translation: \tHe attended many ceremonies.\n",
      "\n",
      "Model output: He asked me a lot of children.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Nos sentamos ahí.\n",
      "Dataset translation: \tWe sat there.\n",
      "\n",
      "Model output: We sat down there.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Es todo.\n",
      "Dataset translation: \tThat is all.\n",
      "\n",
      "Model output: It's all the enemy.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Su vida está llena de problemas.\n",
      "Dataset translation: \tHis life is full of trouble.\n",
      "\n",
      "Model output: His family is very well.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué estás esperando?\n",
      "Dataset translation: \tWhat are you waiting for?\n",
      "\n",
      "Model output: What are you waiting for?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cómo puedes aguantarlo?\n",
      "Dataset translation: \tHow can you stand it?\n",
      "\n",
      "Model output: How can you pay it?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: María perdió sus lentes de lectura.\n",
      "Dataset translation: \tMary lost her reading glasses.\n",
      "\n",
      "Model output: Mary lost his rest for his room.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ahora lo digo de veras.\n",
      "Dataset translation: \tI mean it this time.\n",
      "\n",
      "Model output: I'm saying now.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ellos eran hombres conservadores.\n",
      "Dataset translation: \tThey were conservative men.\n",
      "\n",
      "Model output: They were made to make many children.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Quisiera una taza de té.\n",
      "Dataset translation: \tI'd like a cup of tea.\n",
      "\n",
      "Model output: I'd like a beautiful food.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué intenta esconder?\n",
      "Dataset translation: \tWhat are you trying to hide?\n",
      "\n",
      "Model output: What is they trying to stay?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: A Tom no le gustó Mary.\n",
      "Dataset translation: \tTom didn't like Mary.\n",
      "\n",
      "Model output: Tom didn't like Mary.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué intentáis ocultar?\n",
      "Dataset translation: \tWhat are you trying to hide?\n",
      "\n",
      "Model output: What do you try to stand?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: La táctica funcionó.\n",
      "Dataset translation: \tThe tactic worked.\n",
      "\n",
      "Model output: The children was smoking.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Vine por ustedes.\n",
      "Dataset translation: \tI came for you.\n",
      "\n",
      "Model output: I came from you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Te debo algo?\n",
      "Dataset translation: \tDo I owe you something?\n",
      "\n",
      "Model output: Do I have something to stay?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Me ayudas a mover la mesa?\n",
      "Dataset translation: \tCan you help me move the table?\n",
      "\n",
      "Model output: Can you help me the door?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom arriesgó su vida para salvar a Mary.\n",
      "Dataset translation: \tTom risked his life to save Mary.\n",
      "\n",
      "Model output: Tom respected Mary to his family.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: He comprado aquí durante siglos.\n",
      "Dataset translation: \tI've shopped here for ages.\n",
      "\n",
      "Model output: I bought his sister for her.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Até a mi perro a un árbol del jardín.\n",
      "Dataset translation: \tI tied my dog to a tree in the garden.\n",
      "\n",
      "Model output: I attend my author on the train to the bank.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Soy de Kioto.\n",
      "Dataset translation: \tI'm from Kyoto.\n",
      "\n",
      "Model output: I'm on Kyoto.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Las niñas no jugarán al tenis mañana.\n",
      "Dataset translation: \tThe girls will not play tennis tomorrow.\n",
      "\n",
      "Model output: Children are not playing tonight.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Todas las mañanas voy de compras.\n",
      "Dataset translation: \tI go shopping every morning.\n",
      "\n",
      "Model output: I always go to be careful.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo que plantar árboles en el jardín.\n",
      "Dataset translation: \tI have to plant trees in the garden.\n",
      "\n",
      "Model output: I have to play the window in the window.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Para servir o para llevar?\n",
      "Dataset translation: \tFor here, or to go?\n",
      "\n",
      "Model output: Is it so going to be a lot of fast?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cómo supiste que iba a pasar eso?\n",
      "Dataset translation: \tHow did you know that was going to happen?\n",
      "\n",
      "Model output: How did you know what I should do?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom murió en un accidente de tráfico.\n",
      "Dataset translation: \tTom died in a traffic accident.\n",
      "\n",
      "Model output: Tom died a problem in the complain.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ya no estoy casada con Tom.\n",
      "Dataset translation: \tI'm no longer married to Tom.\n",
      "\n",
      "Model output: I'm not almost Tom with me.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No es un reloj.\n",
      "Dataset translation: \tIt is not a watch.\n",
      "\n",
      "Model output: It's not a bad.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Te ayudaré si es posible.\n",
      "Dataset translation: \tI will help you if possible.\n",
      "\n",
      "Model output: I'll help you in that it is a first.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ella realmente quería decir el secreto.\n",
      "Dataset translation: \tShe really wanted to tell the secret.\n",
      "\n",
      "Model output: She really wanted to say the story.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ella se tiñó de rubio.\n",
      "Dataset translation: \tShe dyed her hair blonde.\n",
      "\n",
      "Model output: She took his rest.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Has necesitado ayuda alguna vez?\n",
      "Dataset translation: \tHave you ever needed help?\n",
      "\n",
      "Model output: Have you never ever done anything?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: He venido a despedirme.\n",
      "Dataset translation: \tI've come to say goodbye.\n",
      "\n",
      "Model output: I've come to meet me.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Sé que no es una broma.\n",
      "Dataset translation: \tI know it's not a joke.\n",
      "\n",
      "Model output: I know it's not a good book.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Yo cocinaré.\n",
      "Dataset translation: \tI'll cook.\n",
      "\n",
      "Model output: I'll come.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Fuera de mi propiedad.\n",
      "Dataset translation: \tGet off my property.\n",
      "\n",
      "Model output: It was my father.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Puedes venir un momento?\n",
      "Dataset translation: \tWould you come here a moment?\n",
      "\n",
      "Model output: Can you come a little more?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se ve aburrido.\n",
      "Dataset translation: \tTom looks bored.\n",
      "\n",
      "Model output: Tom looks good.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Mira! Hay un avión despegando.\n",
      "Dataset translation: \tLook! There's a plane taking off.\n",
      "\n",
      "Model output: Look at a picture of Sunday, Tom.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Este libro no es mío.\n",
      "Dataset translation: \tThis book isn't mine.\n",
      "\n",
      "Model output: This book isn't mine.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom bebe.\n",
      "Dataset translation: \tTom drinks.\n",
      "\n",
      "Model output: Tom drinks.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Cuando lo oyó, le entraron ganas de llorar.\n",
      "Dataset translation: \tWhen she heard that, she felt like crying.\n",
      "\n",
      "Model output: When I heard her family, I had a little come.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seq2seq_util import test_predictions\n",
    "\n",
    "test_predictions(valid_samples[:100], inf_encoder, inf_decoder, encode_batch, translate_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Después de una larga espera pudimos entrar.\n",
      "Dataset translation: \tWe got in after a long wait.\n",
      "\n",
      "Model output: After a lot of watching a country.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Lo siento, pero es imposible.\n",
      "Dataset translation: \tI'm sorry, but it's impossible.\n",
      "\n",
      "Model output: I'm sorry, is it is important.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Parecía satisfecho.\n",
      "Dataset translation: \tHe looked pleased.\n",
      "\n",
      "Model output: He seemed surprised.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Saqué el pastel del horno.\n",
      "Dataset translation: \tI took the cake out of the oven.\n",
      "\n",
      "Model output: I took the party the bank.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Es un trabajo muy difícil.\n",
      "Dataset translation: \tThat's a very tough job.\n",
      "\n",
      "Model output: It's a very difficult discountry.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Dijiste que no entendías.\n",
      "Dataset translation: \tYou said you didn't understand.\n",
      "\n",
      "Model output: You said you didn't say it.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Todo el mundo te está esperando.\n",
      "Dataset translation: \tEverybody is waiting for you.\n",
      "\n",
      "Model output: Everybody wants for you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Recuerdo lo que era.\n",
      "Dataset translation: \tI remember what it was.\n",
      "\n",
      "Model output: I remember what I was doing.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom aterrizó su helicóptero sobre el techo.\n",
      "Dataset translation: \tTom landed his helicopter on the roof.\n",
      "\n",
      "Model output: Tom his advice of his father in the room.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom pidió direcciones.\n",
      "Dataset translation: \tTom asked for directions.\n",
      "\n",
      "Model output: Tom asked for a discount.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Él tiene una personalidad dócil.\n",
      "Dataset translation: \tHe has a mild nature.\n",
      "\n",
      "Model output: He has a perfect party.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Hago ejercicios dos horas por día.\n",
      "Dataset translation: \tI exercise for two hours every day.\n",
      "\n",
      "Model output: I do the day for school at six.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No me creerán aunque les jure que es cierto.\n",
      "Dataset translation: \tThey won't believe me even if I swear it is true.\n",
      "\n",
      "Model output: They won't believe me that it's really good at the rest.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: He dado el primer paso.\n",
      "Dataset translation: \tI've taken the first step.\n",
      "\n",
      "Model output: I've got the party for the first.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom y yo trabajamos juntos.\n",
      "Dataset translation: \tTom and I work together.\n",
      "\n",
      "Model output: Tom and I worked for all the first.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Él es mucho mejor que tú.\n",
      "Dataset translation: \tHe is much better than you.\n",
      "\n",
      "Model output: He is very better than you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ven cualquier día que quieras.\n",
      "Dataset translation: \tCome on any day you like.\n",
      "\n",
      "Model output: Come anything you want to see you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: El gerente dijo que era culpa tuya.\n",
      "Dataset translation: \tThe manager said it was your fault.\n",
      "\n",
      "Model output: The same was too her favorite was you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom murió feliz.\n",
      "Dataset translation: \tTom died happy.\n",
      "\n",
      "Model output: Tom died happy.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Le vi nuevamente.\n",
      "Dataset translation: \tI saw him again.\n",
      "\n",
      "Model output: I saw him now.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ella dejó a los niños al cuidado de su tía.\n",
      "Dataset translation: \tShe left her children in her aunt's care.\n",
      "\n",
      "Model output: She left the book on the box with your car.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: El arte no es un lujo, sino una necesidad.\n",
      "Dataset translation: \tArt is not a luxury, but a necessity.\n",
      "\n",
      "Model output: Long isn't a little and in the complain.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Había todo tipo de actividades grupales.\n",
      "Dataset translation: \tThere were all sorts of group activities.\n",
      "\n",
      "Model output: There was all a lot of friends of the car.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Él te aconsejará al respecto.\n",
      "Dataset translation: \tHe will advise you on that matter.\n",
      "\n",
      "Model output: He will ask you to find the party.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tú no eres japonés.\n",
      "Dataset translation: \tYou are not Japanese.\n",
      "\n",
      "Model output: You are not Japanese.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo que cocinar la cena hoy.\n",
      "Dataset translation: \tI have to cook dinner today.\n",
      "\n",
      "Model output: I have to get to the cold today.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Soy mejor.\n",
      "Dataset translation: \tI am better.\n",
      "\n",
      "Model output: I'm better.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Te queda bien.\n",
      "Dataset translation: \tThat looks good on you.\n",
      "\n",
      "Model output: That stop good.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Cenaremos juntos y luego iremos al teatro.\n",
      "Dataset translation: \tWe'll dine together and then go to the theater.\n",
      "\n",
      "Model output: We'll get alone to the party and start the time.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Pasemos adentro.\n",
      "Dataset translation: \tLet's step inside.\n",
      "\n",
      "Model output: Let's stay at him.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No me puedo costear un auto nuevo.\n",
      "Dataset translation: \tI can't afford a new car.\n",
      "\n",
      "Model output: I can't come any more the way.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: «¿A qué hora os levantáis?»«A las ocho.»\n",
      "Dataset translation: \t\"What time do you guys wake up?\" \"Eight o'clock.\"\n",
      "\n",
      "Model output: \"What time do you get up at the news?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Es un error decir mentiras.\n",
      "Dataset translation: \tIt is wrong to tell a lie.\n",
      "\n",
      "Model output: It's a mistake to make mistakes.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ellos me mostraron muchas fotos hermosas.\n",
      "Dataset translation: \tThey showed me a lot of beautiful photos.\n",
      "\n",
      "Model output: They shot me a lot of family for movies.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ojalá pudiera bailar todos los días.\n",
      "Dataset translation: \tI wish I could dance every day.\n",
      "\n",
      "Model output: I wish I could stop all day.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Intenté escribir con la mano izquierda.\n",
      "Dataset translation: \tI tried writing with my left hand.\n",
      "\n",
      "Model output: I tried to write with him when I was a little money.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Yo jamás te traicionaría.\n",
      "Dataset translation: \tI'd never betray you.\n",
      "\n",
      "Model output: I'd never get your father.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tomás canta bastante bien.\n",
      "Dataset translation: \tTom sings quite well.\n",
      "\n",
      "Model output: Tom says well well.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Yo sé conducir un coche, pero Tom no.\n",
      "Dataset translation: \tI can drive a car, but Tom can't.\n",
      "\n",
      "Model output: I know a country to do with Tom.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom se portó, para ser un principiante.\n",
      "Dataset translation: \tTom did well for a beginner.\n",
      "\n",
      "Model output: Tom become a problem to be a problem.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Lo traeré de vuelta.\n",
      "Dataset translation: \tI'll bring it back.\n",
      "\n",
      "Model output: I'll believe it from him.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Casi tengo treinta años.\n",
      "Dataset translation: \tI'm almost thirty.\n",
      "\n",
      "Model output: I'm almost tired today.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom observa a Mary.\n",
      "Dataset translation: \tTom watches Mary.\n",
      "\n",
      "Model output: Tom looks Mary.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Quieres verlo?\n",
      "Dataset translation: \tDo you want to see it?\n",
      "\n",
      "Model output: Do you want to see it?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Qué tiene ella?\n",
      "Dataset translation: \tWhat does she have?\n",
      "\n",
      "Model output: What does that he?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: La mayoría de la gente no lo haría así.\n",
      "Dataset translation: \tMost people wouldn't do that that way.\n",
      "\n",
      "Model output: Most was not to do that he was so much.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Leí el libro entero.\n",
      "Dataset translation: \tI read the entire book.\n",
      "\n",
      "Model output: I read the book at the book.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tienes que responder a la pregunta.\n",
      "Dataset translation: \tYou need to answer the question.\n",
      "\n",
      "Model output: You must respect the problem.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Has vivido aquí?\n",
      "Dataset translation: \tDid you live here?\n",
      "\n",
      "Model output: Did you live here?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: He decidido hacer eso solo.\n",
      "Dataset translation: \tI've decided to do that by myself.\n",
      "\n",
      "Model output: I've decided to do that anymore.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Ella le vio comerse un sándwich.\n",
      "Dataset translation: \tShe saw him eating a sandwich.\n",
      "\n",
      "Model output: She saw him something to speak.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No quiero esta camisa.\n",
      "Dataset translation: \tI don't want this shirt.\n",
      "\n",
      "Model output: I don't want this car.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Él se marchó hace diez minutos.\n",
      "Dataset translation: \tHe left ten minutes ago.\n",
      "\n",
      "Model output: He has destroved the months ago.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Sabes por qué Tom vino aquí hoy?\n",
      "Dataset translation: \tDo you know the reason Tom came here today?\n",
      "\n",
      "Model output: Do you know why Tom came here for you?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Me podrías pasar la sal, por favor?\n",
      "Dataset translation: \tCould you pass me the salt, please?\n",
      "\n",
      "Model output: Could you please stay my parent?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No le gustan las cosas dulces.\n",
      "Dataset translation: \tHe doesn't care for sweet things.\n",
      "\n",
      "Model output: He doesn't like sports.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Hoy es jueves.\n",
      "Dataset translation: \tToday is Thursday.\n",
      "\n",
      "Model output: Today's tennis today.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom no se ha sentido muy bien recientemente.\n",
      "Dataset translation: \tTom hasn't been very well recently.\n",
      "\n",
      "Model output: Tom hasn't feel very singing well.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Todo lo que sé es que él viene de China.\n",
      "Dataset translation: \tAll I know is that he came from China.\n",
      "\n",
      "Model output: All I know what he is coming to China.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Dígame cuando desee hacer su orden.\n",
      "Dataset translation: \tTell me when you'd like to order.\n",
      "\n",
      "Model output: Tell me when you do the book with him.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Qué perro más grande!\n",
      "Dataset translation: \tWhat a huge dog!\n",
      "\n",
      "Model output: What a beautiful person.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Conseguimos llegar allá a tiempo.\n",
      "Dataset translation: \tWe managed to get there on time.\n",
      "\n",
      "Model output: We made the train to go to the evening.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Vete ya!\n",
      "Dataset translation: \tGo away.\n",
      "\n",
      "Model output: Go away.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Él me envió una tarjeta de cumpleaños.\n",
      "Dataset translation: \tHe sent me a birthday card.\n",
      "\n",
      "Model output: He sent me a cold of children a lot.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No te recuerdo.\n",
      "Dataset translation: \tI don't remember you.\n",
      "\n",
      "Model output: I don't remember you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Quiero hacerlo tan a menudo como pueda.\n",
      "Dataset translation: \tI want to do that as often as I can.\n",
      "\n",
      "Model output: I want to do it as I can do anything.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Para qué se está escondiendo Tom?\n",
      "Dataset translation: \tWhat's Tom hiding for?\n",
      "\n",
      "Model output: What's Tom hiding with us?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Me da una enchinada.\n",
      "Dataset translation: \tIt creeps me out.\n",
      "\n",
      "Model output: I go a little me.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tom nunca lastimaría a sus hijos.\n",
      "Dataset translation: \tTom would never hurt his children.\n",
      "\n",
      "Model output: Tom wouldn't have any children his dog.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Consiguió que la máquina funcionara.\n",
      "Dataset translation: \tHe managed to run the machine.\n",
      "\n",
      "Model output: He got the word to make me.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¡Bienvenido a tu nuevo hogar!\n",
      "Dataset translation: \tWelcome to your new home.\n",
      "\n",
      "Model output: Welcome your new day.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Yo hice esta silla.\n",
      "Dataset translation: \tI made this chair.\n",
      "\n",
      "Model output: I made this story.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Te traje café.\n",
      "Dataset translation: \tI brought you some coffee.\n",
      "\n",
      "Model output: I brought you coffee.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Má, ¡apúrate! Están todos esperando.\n",
      "Dataset translation: \tMom, hurry up! Everyone's waiting.\n",
      "\n",
      "Model output: Ohe ! We're an expensive, are you.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: El viernes es cuando estoy menos ocupado.\n",
      "Dataset translation: \tFriday is when I am least busy.\n",
      "\n",
      "Model output: The singling is when I am coming before.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Creo que el tren vendrá pronto.\n",
      "Dataset translation: \tI think the train will come soon.\n",
      "\n",
      "Model output: I think that he is true.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: El sombrero estaba sucio por arriba.\n",
      "Dataset translation: \tThe hat was dirty around the top.\n",
      "\n",
      "Model output: The must was surprised for him.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Por favor, hable más rápido.\n",
      "Dataset translation: \tPlease speak more quickly.\n",
      "\n",
      "Model output: Please speak fast.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: El despertador sonó.\n",
      "Dataset translation: \tThe alarm went off.\n",
      "\n",
      "Model output: The desk was a lot.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Los ricos tienen muchos amigos.\n",
      "Dataset translation: \tThe rich have many friends.\n",
      "\n",
      "Model output: The river has a book friends.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No confíe en él.\n",
      "Dataset translation: \tDon't trust him.\n",
      "\n",
      "Model output: Don't trust him.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Habló del accidente?\n",
      "Dataset translation: \tDid he mention the accident?\n",
      "\n",
      "Model output: Did they speak the party?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy desempleada.\n",
      "Dataset translation: \tI'm unemployed.\n",
      "\n",
      "Model output: I'm away.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No todo estudiante tiene un diccionario.\n",
      "Dataset translation: \tNot every student has a dictionary.\n",
      "\n",
      "Model output: Not study as a difficult time is a dictionary.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Estoy cerrando mi tienda.\n",
      "Dataset translation: \tI'm closing my store.\n",
      "\n",
      "Model output: I'm complaining my decision.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tengo un caballo blanco.\n",
      "Dataset translation: \tI've got a white horse.\n",
      "\n",
      "Model output: I have a big complain.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Debemos cumplir sus órdenes.\n",
      "Dataset translation: \tWe must execute his orders.\n",
      "\n",
      "Model output: We must change his children.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Qué será, será.\n",
      "Dataset translation: \tWhatever will be, will be.\n",
      "\n",
      "Model output: He will be being to stay.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No parece alegrarse de vernos.\n",
      "Dataset translation: \tHe doesn't look happy to see us.\n",
      "\n",
      "Model output: He doesn't seem to see us at six.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Lo firmaré mañana.\n",
      "Dataset translation: \tI'll sign it tomorrow.\n",
      "\n",
      "Model output: I'll see it tomorrow.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Cuál es tu equipo de fútbol favorito?\n",
      "Dataset translation: \tWhat's your favorite soccer team?\n",
      "\n",
      "Model output: What's your favorite for a bit for?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Tu ayuda nos va a ahorrar mucho trabajo.\n",
      "Dataset translation: \tYour help will save us a lot of work.\n",
      "\n",
      "Model output: Your house is very going to do anything about the water.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: El niño se ensució las manos.\n",
      "Dataset translation: \tThe boy got his hands dirty.\n",
      "\n",
      "Model output: The boy came his story.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Usted debe ser el nuevo profesor.\n",
      "Dataset translation: \tYou must be the new teacher.\n",
      "\n",
      "Model output: You must be the new problem.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: ¿Quién se robó mi canasto con la carne?\n",
      "Dataset translation: \tWho stole my basket with the meat?\n",
      "\n",
      "Model output: Who stopped my car in the car?\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No estaba manejando tan rápido.\n",
      "Dataset translation: \tI wasn't driving all that fast.\n",
      "\n",
      "Model output: I wasn't traveling as so happy.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Están muy lejos.\n",
      "Dataset translation: \tThey are very far away.\n",
      "\n",
      "Model output: They're very beautiful.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "Input sentence: Ella hizo un viaje a Europa el mes pasado.\n",
      "Dataset translation: \tShe made a trip to Europe last month.\n",
      "\n",
      "Model output: She made a problem in the complain in the complain.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: No tengo tiempo para juegos.\n",
      "Dataset translation: \tI don't have time for games.\n",
      "\n",
      "Model output: I don't have time to be a lot.\n",
      "\n",
      "-----------------------------------------\n",
      "Input sentence: Compré esta cámara por 25.000 yenes.\n",
      "Dataset translation: \tI bought this camera for 25,000 yen.\n",
      "\n",
      "Model output: I bought this cold of 200 police of 20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions(train_samples[:100], inf_encoder, inf_decoder, encode_batch, translate_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model in Core ML format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_enc_in = Input(shape=(None, in_vocab_size), name=\"encoder_in\")\n",
    "coreml_enc_lstm = LSTM(latent_dim, return_state=True, name=\"encoder_lstm\")\n",
    "coreml_enc_out, _, _ = coreml_enc_lstm(coreml_enc_in)\n",
    "\n",
    "coreml_encoder_model = Model(coreml_enc_in, coreml_enc_out)\n",
    "coreml_encoder_model.output_layers = coreml_encoder_model._output_layers\n",
    "\n",
    "inf_encoder.save_weights(\"Es2EnCharEncoderWeights.h5\")\n",
    "coreml_encoder_model.load_weights(\"Es2EnCharEncoderWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : encoder_in, <keras.engine.input_layer.InputLayer object at 0x7fe03a50ff60>\n",
      "1 : encoder_lstm, <keras.layers.recurrent.LSTM object at 0x7fe03a50fa58>\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "\n",
    "coreml_encoder = coremltools.converters.keras.convert(\n",
    "    coreml_encoder_model,\n",
    "    input_names=\"encodedSeq\",\n",
    "    output_names=\"ignored\")\n",
    "\n",
    "coreml_encoder.save(\"Es2EnCharEncoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_dec_in = Input(shape=(None, out_vocab_size))\n",
    "\n",
    "coreml_dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "coreml_dec_lstm_out, _, _ = coreml_dec_lstm(coreml_dec_in)\n",
    "coreml_dec_dense = Dense(out_vocab_size, activation=\"softmax\")\n",
    "coreml_dec_out = coreml_dec_dense(coreml_dec_lstm_out)\n",
    "\n",
    "coreml_decoder_model = Model(coreml_dec_in, coreml_dec_out)\n",
    "coreml_decoder_model.output_layers = coreml_decoder_model._output_layers\n",
    "\n",
    "inf_decoder.save_weights(\"Es2EnCharDecoderWeights.h5\")\n",
    "coreml_decoder_model.load_weights(\"Es2EnCharDecoderWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : input_1, <keras.engine.input_layer.InputLayer object at 0x7fe038de9e10>\n",
      "1 : decoder_lstm, <keras.layers.recurrent.LSTM object at 0x7fe038de9e48>\n",
      "2 : dense_1, <keras.layers.core.Dense object at 0x7fe038de9eb8>\n",
      "3 : dense_1__activation__, <keras.layers.core.Activation object at 0x7fe038de9630>\n"
     ]
    }
   ],
   "source": [
    "coreml_decoder = coremltools.converters.keras.convert(\n",
    "    coreml_decoder_model,\n",
    "    input_names=\"encodedChar\",\n",
    "    output_names=\"nextCharProbs\")\n",
    "\n",
    "coreml_decoder.save(\"Es2EnCharDecoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert weights to 16bit floats. This shouldn't hurt performance much, if at all, and it reduces the app's download size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_fp16(mlmodel_filename):\n",
    "    basename = mlmodel_filename[:-len(\".mlmodel\")]\n",
    "    spec = coremltools.utils.load_spec(mlmodel_filename)\n",
    "    spec_16bit = \\\n",
    "      coremltools.utils.convert_neural_network_spec_weights_to_fp16(spec)\n",
    "    coremltools.utils.save_spec(spec_16bit, f\"{basename}16Bit.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_fp16(\"Es2EnCharEncoder.mlmodel\")\n",
    "convert_to_fp16(\"Es2EnCharDecoder.mlmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the maps so you can transform text to and from ints. You'll need them later in the iOS app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"esCharToInt.json\", \"w\") as f:\n",
    "    json.dump(in_token2int, f)\n",
    "with open(\"intToEnChar.json\", \"w\") as f:\n",
    "    json.dump(out_int2token, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
